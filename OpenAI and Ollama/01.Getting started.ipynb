{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e7797d5",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "In this quickstart we will see how to:\n",
    "1. Get set up with LangChain, LangSmith and LangServe\n",
    "2. Use the most basic and common components of LangChain: prompt templates, models and output parsers\n",
    "3. Build a simple application with Langchain\n",
    "4. Trace the application with LangSmith\n",
    "5. Serve the application with LangServe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb628861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY: sk-proj-ID***tIA\n",
      "LANGCHAIN_API_KEY: lsv2_pt_64***43b\n",
      "LANGCHAIN_PROJECT: LangChain tutorial get started\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load the environment variables in .env file\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.environ['OPENAI_API_KEY']\n",
    "print(f'OPENAI_API_KEY: {OPENAI_API_KEY[:10]}***{OPENAI_API_KEY[-3:]}')\n",
    "\n",
    "# We will use LANGCHAIN_API_KEY for LangSmith tracking\n",
    "LANGCHAIN_API_KEY = os.environ['LANGCHAIN_API_KEY']\n",
    "print(f'LANGCHAIN_API_KEY: {LANGCHAIN_API_KEY[:10]}***{LANGCHAIN_API_KEY[-3:]}')\n",
    "\n",
    "# Required by LangChain \n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "LANGCHAIN_PROJECT = os.environ['LANGCHAIN_PROJECT']\n",
    "print(f'LANGCHAIN_PROJECT: {LANGCHAIN_PROJECT}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c5249a",
   "metadata": {},
   "source": [
    "One of the questions when we work with LLMs is, what kind of models we can actually use?\n",
    "\n",
    "For OpenAI we can find the models in [OpenAI docs](http://platform.openai.com/docs/models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd1ea19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x1175192b0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x117519d30> root_client=<openai.OpenAI object at 0x116956900> root_async_client=<openai.AsyncOpenAI object at 0x117519a90> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model='gpt-4o', api_key=OPENAI_API_KEY)\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb15ee3",
   "metadata": {},
   "source": [
    "Asking a question. We need to provide **input** and we will get a **response** from the LLM. Because we have a `LANGCHAIN_API_KEY` set and also `LANGCHAIN_TRACING_V2` set to **true**, all the requests/responses will be stored in [LangSmith](http://smith.langchain.com/o/a9402f23-0cd4-4009-8f20-15b305f46b4f/projects/p/c2b7c2c3-ca78-46bf-bfc0-fdee6a119ba9?timeModel=%7B%22duration%22%3A%227d%22%7D&peek=4b5d482e-cbc8-470b-b8dc-8f1162ef4952&peeked_trace=4b5d482e-cbc8-470b-b8dc-8f1162ef4952)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36598b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"GenAI, short for Generative Artificial Intelligence, refers to a subset of artificial intelligence that focuses on creating or generating new content. This can include text, images, music, and more, based on input data or prompts. GenAI models, such as OpenAI's GPT-3, DALL-E, and Google's Imagen, utilize deep learning techniques, particularly neural networks, to produce outputs that mimic human creativity or resemble real-world data.\\n\\nThese models are trained on large datasets and can understand and produce human-like language, create visuals that resemble photographs or artwork, compose music, and even code. The potential applications of GenAI are vast, impacting industries such as entertainment, design, marketing, and even software development. However, they also raise ethical and societal questions regarding originality, ownership, and the potential for misuse.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 163, 'prompt_tokens': 12, 'total_tokens': 175, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_46bff0e0c8', 'id': 'chatcmpl-C7ax3pqOcSbc39Zl56L1U74qWB8zQ', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--4b5d482e-cbc8-470b-b8dc-8f1162ef4952-0', usage_metadata={'input_tokens': 12, 'output_tokens': 163, 'total_tokens': 175, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = 'What is GenAI?'\n",
    "\n",
    "response = llm.invoke(input=input)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91de918d",
   "metadata": {},
   "source": [
    "### Prompt template\n",
    "\n",
    "**Prompt template** is how you want the LLM to behave or what kind of role you want your LLM to be. \n",
    "Example: Act as an AI engineer and provide me suggestions how to develop AI project.\n",
    "\n",
    "\n",
    "**ChatPromptTemplate** \n",
    "When we create a ChatPromptTemplate we define the prompt as a list of tuples. Each tuple "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c808e786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['input'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are expert AI engineer. Provide me answers based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    # System\n",
    "    ('system', 'You are expert AI engineer. Provide me answers based on the question'),\n",
    "    # User. User will provide some input with {input} placeholder\n",
    "    ('user', '{input}')\n",
    "])\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d8141c",
   "metadata": {},
   "source": [
    "Now let's use this **prompt template** along with the LLM model. For that we will create a **chain**. Chain is create like `chain = prompt|llm`. So whenever we give any input to the chain:\n",
    "- It will go to the prompt \n",
    "- Go to the LLM\n",
    "- Return the response\n",
    "\n",
    "We are calling the chain with `invoke()` method and we need to pass all the input variables from the prompt as a `dict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dde62bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='LangSmith is a platform or tool designed to enhance and optimize the development, testing, and monitoring of applications built using large language models (LLMs). It aims to address the challenges developers face when working with LLM-based applications by offering features for debugging, testing, evaluating performance, and integrating seamlessly into existing workflows. LangSmith typically supports applications built with popular frameworks like LangChain, providing functionalities that help ensure the cutting-edge performance, reliability, and efficiency of language model implementations.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 95, 'prompt_tokens': 33, 'total_tokens': 128, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_46bff0e0c8', 'id': 'chatcmpl-C7bK85PAb1noSOWUydmw7bW0owhWU', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--5bf6e133-6ac5-4ca2-b585-cfb6e892a763-0' usage_metadata={'input_tokens': 33, 'output_tokens': 95, 'total_tokens': 128, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm\n",
    "response = chain.invoke({'input', 'What is LangSmith?'})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fd74da",
   "metadata": {},
   "source": [
    "#### Output parser\n",
    "Output parser get the message from LLM and transforms it How we want to display it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6272bfde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Singular Value Decomposition (SVD) and Principal Component Analysis (PCA) are both techniques used in data analysis and dimensionality reduction, but they have different applications and interpretations:\n",
      "\n",
      "1. **Purpose and Application**:\n",
      "   - **SVD**: It is a mathematical technique used to factorize a matrix into three matrices (U, Σ, V*). SVD is a more general method and can be applied to any real or complex matrix. It's widely used not only in dimensionality reduction but also in signal processing, image compression, and solving systems of linear equations.\n",
      "   - **PCA**: This is a specific statistical technique used to identify the directions (principal components) that maximize the variance in a dataset. PCA is primarily used for dimensionality reduction and exploratory data analysis to simplify the complexity of the data while retaining as much variance as possible.\n",
      "\n",
      "2. **Mathematical Relationship**:\n",
      "   - PCA is essentially a specific application of SVD. When you perform PCA, you typically center the data (by subtracting the mean) and perform SVD on the covariance matrix of the data. The principal components are derived from the eigenvectors of the covariance matrix, which correspond to the right singular vectors (V) from the SVD.\n",
      "\n",
      "3. **Data Requirements**:\n",
      "   - **SVD**: Can be performed on any matrix, regardless of whether it's square or not.\n",
      "   - **PCA**: Usually performed on centered data (mean of zero) and is primarily applicable to datasets where the number of observations is greater than the number of variables.\n",
      "\n",
      "4. **Output and Interpretation**:\n",
      "   - **SVD**: Decomposes a matrix into U (left singular vectors), Σ (diagonal matrix of singular values), and V* (right singular vectors). The singular values in Σ provide a measure of the importance or weight of the corresponding dimensions.\n",
      "   - **PCA**: Provides principal components, which are linear combinations of the original variables. These components are ranked by the amount of variance they explain in the data. The eigenvalues indicate the variance captured by each principal component.\n",
      "\n",
      "5. **Scaling**:\n",
      "   - **SVD**: Does not inherently involve data scaling or normalization, although it can be applied to standardized or normalized matrices.\n",
      "   - **PCA**: Often performed on standardized data (subtracting the mean and dividing by the standard deviation) to ensure that each variable contributes equally to the analysis.\n",
      "\n",
      "In summary, while SVD and PCA are related, SVD is a general-purpose matrix factorization method, whereas PCA is a specific technique for dimensionality reduction based on maximizing variance along orthogonal directions derived from the input data.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "response = chain.invoke({'input', 'What is the difference between SVD and PCA?'})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd945c5",
   "metadata": {},
   "source": [
    "fr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
